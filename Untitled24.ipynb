{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is Logistic Regression, and how does it differ from Linear\n",
        "Regression?"
      ],
      "metadata": {
        "id": "lMbvNDk4SXki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: Logistic Regression:\n",
        "Logistic Regression is a supervised machine learning algorithm used primarily for classification problemsâ€”especially binary classification (i.e., predicting one of two possible outcomes such as yes/no, spam/ham, 0/1, disease/no disease, etc.).\n",
        "\n",
        "Instead of predicting a continuous output (as in linear regression), logistic regression predicts the probability that a given input point belongs to a particular class.\n",
        "\n",
        "The core idea is to use the logistic (sigmoid) function to map any real-valued number into the range (0, 1):\n",
        "\n",
        "ðœŽ\n",
        "(\n",
        "ð‘§\n",
        ")\n",
        "=\n",
        "1\n",
        "1\n",
        "+\n",
        "ð‘’\n",
        "âˆ’\n",
        "ð‘§\n",
        ",\n",
        "where\n",
        "ð‘§\n",
        "=\n",
        "ð›½\n",
        "0\n",
        "+\n",
        "ð›½\n",
        "1\n",
        "ð‘¥\n",
        "1\n",
        "+\n",
        "ð›½\n",
        "2\n",
        "ð‘¥\n",
        "2\n",
        "+\n",
        "â‹¯\n",
        "+\n",
        "ð›½\n",
        "ð‘›\n",
        "ð‘¥\n",
        "ð‘›\n",
        "Ïƒ(z)=\n",
        "1+e\n",
        "âˆ’z\n",
        "\n",
        "1\n",
        "â€‹\n",
        " ,whereÂ z=Î²\n",
        "0\n",
        "â€‹\n",
        " +Î²\n",
        "1\n",
        "â€‹\n",
        " x\n",
        "1\n",
        "â€‹\n",
        " +Î²\n",
        "2\n",
        "â€‹\n",
        " x\n",
        "2\n",
        "â€‹\n",
        " +â‹¯+Î²\n",
        "n\n",
        "â€‹\n",
        " x\n",
        "n\n",
        "â€‹\n",
        "\n",
        "If the output probability is greater than a certain threshold (commonly 0.5), the instance is classified as class 1; otherwise, class 0.\n",
        "\n",
        "| Aspect               | Linear Regression                                 | Logistic Regression                                    |\n",
        "| -------------------- | ------------------------------------------------- | ------------------------------------------------------ |\n",
        "| **Type of Problem**  | Regression (predicting continuous value)          | Classification (predicting class label or probability) |\n",
        "| **Output Range**     | Real numbers (-âˆž to âˆž)                            | Probability (0 to 1)                                   |\n",
        "| **Function Used**    | Linear function                                   | Sigmoid (logistic) function                            |\n",
        "| **Model Equation**   | $y = \\beta_0 + \\beta_1 x_1 + \\dots + \\beta_n x_n$ | $p = \\frac{1}{1 + e^{-z}}$                             |\n",
        "| **Loss Function**    | Mean Squared Error (MSE)                          | Log Loss (Binary Cross-Entropy)                        |\n",
        "| **Use Case Example** | Predicting house prices                           | Predicting if an email is spam or not                  |\n"
      ],
      "metadata": {
        "id": "IhvtBxsqSZ__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Explain the role of the Sigmoid function in Logistic Regression"
      ],
      "metadata": {
        "id": "kO-23unoS32o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : In Logistic Regression, the model needs to predict the probability that a given input belongs to a particular class (usually binary: 0 or 1). The sigmoid function (also known as the logistic function) plays a central role in making this possible.\n",
        "\n",
        "| Role                                         | Explanation                                                                                                                                                                                             |\n",
        "| -------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **1. Converts Linear Output to Probability** | The linear combination $z$ can take any value between $-\\infty$ to $\\infty$. The sigmoid function squashes this value into a **bounded range (0 to 1)**, which can be interpreted as a **probability**. |\n",
        "| **2. Enables Classification**                | After calculating the probability $\\hat{y} = \\sigma(z)$, logistic regression applies a threshold (usually 0.5). If $\\hat{y} > 0.5$, predict class 1; else, predict class 0.                             |\n",
        "| **3. Makes Optimization Feasible**           | The sigmoid function is **differentiable**, which allows optimization algorithms like **gradient descent** to efficiently minimize the loss (usually **log loss** or **binary cross-entropy**).         |\n",
        "| **4. Helps Interpret Model Output**          | The output of the sigmoid function is easily interpretable: a value of 0.9 means the model is 90% confident the input belongs to class 1.                                                               |\n"
      ],
      "metadata": {
        "id": "xt1ReF6pTxnR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What is Regularization in Logistic Regression and why is it needed?\n"
      ],
      "metadata": {
        "id": "IKKWFWOWT6OH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: Regularization is a technique used in logistic regression (and other machine learning models) to prevent overfitting by penalizing large or unnecessary coefficients in the model.\n",
        "\n",
        "In simpler terms, regularization discourages the model from becoming too complex, ensuring it generalizes well to unseen dataâ€”not just memorizing the training data.\n",
        "\n",
        "Why is Regularization Needed?\n",
        "1. To Prevent Overfitting:\n",
        "\n",
        "Logistic regression can easily overfit when there are too many features or if some features dominate the prediction due to large weights.\n",
        "\n",
        "Overfitting means the model performs well on training data but poorly on new data.\n",
        "\n",
        "2. To Improve Generalization:\n",
        "\n",
        "Regularization helps the model focus on the most important features and ignore noise or irrelevant information.\n",
        "\n",
        "3. To Handle Multicollinearity:\n",
        "\n",
        "When features are highly correlated, regularization can help stabilize the model by reducing the variance."
      ],
      "metadata": {
        "id": "G0W1qV_pUAkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: What are some common evaluation metrics for classification models, and\n",
        "why are they important?"
      ],
      "metadata": {
        "id": "dCa7JEcKUrIK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "valuation metrics like accuracy, precision, recall, F1-score, and AUC are crucial for understanding a modelâ€™s true performance. They provide more nuanced and situation-specific feedback than accuracy alone. Choosing the right metric ensures your model not only performs well statistically but also meets the real-world goals of your application.\n",
        "\n",
        "| Reason                                           | Explanation                                                                                                                        |\n",
        "| ------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **1. Different Problems Need Different Metrics** | In medical diagnosis, a **false negative** could be fatal â†’ **recall** is more important than accuracy.                            |\n",
        "| **2. Accuracy Can Be Misleading**                | In imbalanced datasets (e.g., 95% class 0, 5% class 1), predicting all zeros gives 95% accuracy but **fails to detect positives**. |\n",
        "| **3. Guides Model Improvement**                  | Metrics highlight model weaknesses (e.g., low recall), helping you **tune or redesign** the model.                                 |\n",
        "| **4. Essential for Model Comparison**            | Helps choose between multiple models (e.g., compare F1 scores or AUC).                                                             |\n"
      ],
      "metadata": {
        "id": "5IAur4HOU6cG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MUKnxyX0U6Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: Write a Python program that loads a CSV file into a Pandas DataFrame,\n",
        "splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.(Use Dataset from sklearn package)"
      ],
      "metadata": {
        "id": "U0CFNz0YVBAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset from sklearn\n",
        "data = load_breast_cancer()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target  # Add target column\n",
        "\n",
        "# Split dataset into features (X) and target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split into train and test sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=10000)  # Increased max_iter to avoid convergence issues\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of the Logistic Regression model: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pvdrQ-_VT2h",
        "outputId": "03504c6d-a34c-4d15-c8db-17f7ea51c0ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the Logistic Regression model: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: Write a Python program to train a Logistic Regression model using L2\n",
        "regularization (Ridge) and print the model coefficients and accuracy.\n",
        "(Use Dataset from sklearn package)"
      ],
      "metadata": {
        "id": "rvYRBrnwVqLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset from sklearn\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create Logistic Regression model with L2 regularization (default penalty='l2')\n",
        "model = LogisticRegression(penalty='l2', solver='liblinear', max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Print model coefficients\n",
        "print(\"Model Coefficients:\")\n",
        "for feature, coef in zip(X.columns, model.coef_[0]):\n",
        "    print(f\"{feature}: {coef:.4f}\")\n",
        "\n",
        "# Predict and calculate accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nAccuracy of the L2-Regularized Logistic Regression Model: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxlqB5nlVrH4",
        "outputId": "b7282ca8-b4d4-4fbd-8263-2e766e71ea96"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Coefficients:\n",
            "mean radius: 2.1325\n",
            "mean texture: 0.1528\n",
            "mean perimeter: -0.1451\n",
            "mean area: -0.0008\n",
            "mean smoothness: -0.1426\n",
            "mean compactness: -0.4156\n",
            "mean concavity: -0.6519\n",
            "mean concave points: -0.3445\n",
            "mean symmetry: -0.2076\n",
            "mean fractal dimension: -0.0298\n",
            "radius error: -0.0500\n",
            "texture error: 1.4430\n",
            "perimeter error: -0.3039\n",
            "area error: -0.0726\n",
            "smoothness error: -0.0162\n",
            "compactness error: -0.0019\n",
            "concavity error: -0.0449\n",
            "concave points error: -0.0377\n",
            "symmetry error: -0.0418\n",
            "fractal dimension error: 0.0056\n",
            "worst radius: 1.2321\n",
            "worst texture: -0.4046\n",
            "worst perimeter: -0.0362\n",
            "worst area: -0.0271\n",
            "worst smoothness: -0.2626\n",
            "worst compactness: -1.2090\n",
            "worst concavity: -1.6180\n",
            "worst concave points: -0.6153\n",
            "worst symmetry: -0.7428\n",
            "worst fractal dimension: -0.1170\n",
            "\n",
            "Accuracy of the L2-Regularized Logistic Regression Model: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Write a Python program to train a Logistic Regression model for multiclass\n",
        "classification using multi_class='ovr' and print the classification report.\n",
        "(Use Dataset from sklearn package)"
      ],
      "metadata": {
        "id": "3CiIo8ElV0Ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load Iris dataset (3-class classification)\n",
        "data = load_iris()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression with One-vs-Rest (OvR) strategy\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report (One-vs-Rest):\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=data.target_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upVReGr1V4dI",
        "outputId": "dbaa7b3a-2012-4645-aca9-0ec10ff93617"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report (One-vs-Rest):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      1.00      1.00         9\n",
            "   virginica       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Write a Python program to apply GridSearchCV to tune C and penalty\n",
        "hyperparameters for Logistic Regression and print the best parameters and validation\n",
        "accuracy.\n",
        "(Use Dataset from sklearn package)"
      ],
      "metadata": {
        "id": "-wBnKnKcWEiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']  # liblinear supports both l1 and l2\n",
        "}\n",
        "\n",
        "# Initialize Logistic Regression\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Apply GridSearchCV\n",
        "grid = GridSearchCV(logreg, param_grid, cv=5, scoring='accuracy')\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and score\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(f\"Best Cross-Validation Accuracy: {grid.best_score_:.2f}\")\n",
        "\n",
        "# Evaluate on test data\n",
        "y_pred = grid.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Set Accuracy: {test_accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI2DlKx-WIMu",
        "outputId": "9bd175f6-3edb-439f-baa1-72f998615b58"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best Cross-Validation Accuracy: 0.97\n",
            "Test Set Accuracy: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Write a Python program to standardize the features before training Logistic\n",
        "Regression and compare the model's accuracy with and without scaling.\n",
        "(Use Dataset from sklearn package)"
      ],
      "metadata": {
        "id": "BIAkXxuvWVB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ----------- Model without Scaling -----------\n",
        "model_no_scaling = LogisticRegression(max_iter=1000)\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "print(f\"Accuracy without scaling: {accuracy_no_scaling:.2f}\")\n",
        "\n",
        "# ----------- Model with Standardization -----------\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train logistic regression with scaled features\n",
        "model_scaled = LogisticRegression(max_iter=1000)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "print(f\"Accuracy with standardization: {accuracy_scaled:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8s8iUJ5WY7_",
        "outputId": "ded5e801-bdc3-46eb-aea4-c199832f1ea2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 0.96\n",
            "Accuracy with standardization: 0.97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EwOKijG5WgXM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}